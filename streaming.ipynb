{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = \"/databricks-datasets/structured-streaming/events/\"\n",
    "jsonSchema = StructType([\n",
    "    StructField('time', TimestampType(), True),\n",
    "    StructField('action', StringType(), True ),\n",
    "])\n",
    "streamingInputDF = ( spark\n",
    "    .readStream\n",
    "    .schema(jsonSchema)\n",
    "    .option('maxFilesPerTrigger', 1)\n",
    "    .json(inputPath)\n",
    ")\n",
    "streamingCountsDF = ( streamingInputDF\n",
    "    .groupBy(\n",
    "        streamInputDF.action,\n",
    "        window(streamingInputDF.time, '1 hour')\n",
    "    ).count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ( \n",
    "    streamingCountsDF.writeStream\n",
    "    .format('memory')\n",
    "    .queryName('counts')\n",
    "    .outputMode('complete')\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "select action, \n",
    "    date_format(window.end, 'MMM-dd HH:mm') as time,\n",
    "    count\n",
    "from counts\n",
    "order by time, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
